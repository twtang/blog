{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAYyOFIQCU5D"
      },
      "source": [
        "---\n",
        "title: \"Q4. Expection-Maximization Algorithm (8 points)\"\n",
        "author: \"TW\"\n",
        "date: \"2025-03-29\"\n",
        "categories: python\n",
        "draft: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw5gSbvSA9KF"
      },
      "source": [
        "# Q4. Expectation-Maximization Algorithm (8 points)\n",
        "\n",
        "In this question, you are required to code by yourself to complete the EM algorithm.\n",
        "\n",
        "### Data Descriptions:\n",
        "1. The data is in Data_Q4.csv.\n",
        "2. The test dataset is shown in Q4_Data.csv. There are 6 attributes, which are 'A','B',...,'F', and totally 626 instances in the dataset. You need to cluster all the instances into two classes. Assume the initial centers are c1=(0,0,0,0,0,0) and c2=(1,1,1,1,1,1).\n",
        "\n",
        "### REQUIREMENTS:\n",
        "1. Report the updated centers and SSE for the first two iterations.\n",
        "2. Report the overall iteration step when your algorithm terminates.\n",
        "3. Report the final converged centers for each cluster.\n",
        "\n",
        "### Submissions:\n",
        "1. Put all reports in Q4_readme.pdf.\n",
        "2. Submit your source code in folder Q4_code.\n",
        "3. Put files/folder above in folder Q4.\n",
        "\n",
        "### NOTES:\n",
        "Please use the terminate condition below:\n",
        "\n",
        "**Terminate condition: the EM algorithm will terminate when:**\n",
        "1. The sum of L1-distance for each dimension of old-new center\n",
        "   \\[\n",
        "   \\sum_{\\text{each center}} ||C_{\\text{old}} - C_{\\text{new}}||_1\n",
        "   \\]\n",
        "   is smaller than 0.0001, **or**\n",
        "2. The iteration step is greater than the maximum iteration step 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8CUDaLDA1Eo"
      },
      "source": [
        "Let’s tackle Q4, which involves implementing the Expectation-Maximization (EM) algorithm for clustering a dataset provided in `Data_Q4.csv`. The dataset contains 626 instances with 6 attributes, and we need to cluster them into two clusters (c1 and c2) with specific initial centers. We’ll report the updated centers and Sum of Squared Errors (SSE) for the first two iterations, the final centers when the algorithm converges, and submit the code and report in a folder named `Q4`. Let’s break this down step by step.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 1: Understanding the Problem and Data\n",
        "\n",
        "- **Data Description**:\n",
        "  - `Data_Q4.csv`: Contains 626 instances with 6 attributes (numerical features).\n",
        "  - We need to cluster the data into 2 clusters: c1 and c2.\n",
        "  - Initial centers are given:\n",
        "    - c1 = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    - c2 = (1.1, 1.1, 1.1, 1.1, 1.1, 1.1)\n",
        "\n",
        "- **Task**:\n",
        "  - Implement the EM algorithm for clustering (though this is more akin to Gaussian Mixture Models, the problem seems to describe a k-means-like EM approach with hard assignments).\n",
        "  - Report the updated centers and SSE for the first two iterations.\n",
        "  - Report the final centers when the algorithm converges.\n",
        "  - Submit the code and report in a folder named `Q4`.\n",
        "\n",
        "- **Termination Conditions**:\n",
        "  - The sum of L1-distance between old and new centers for each cluster is smaller than 0.0001, i.e., \\(\\sum_{\\text{each center}} ||C_{\\text{old}} - C_{\\text{new}}||_1 < 0.0001\\).\n",
        "  - The iteration step exceeds the maximum of 100 iterations.\n",
        "\n",
        "#### EM Algorithm for Clustering\n",
        "The EM algorithm is typically used for Gaussian Mixture Models (GMMs), where it iteratively estimates the parameters (means, covariances, and mixing coefficients) of the mixture components. However, the problem description (hard assignments to clusters, L1-distance for convergence, and SSE as a metric) suggests a k-means-like approach with EM terminology. In k-means, the \"E-step\" assigns points to the nearest cluster, and the \"M-step\" updates the cluster centers as the mean of assigned points. We’ll implement this interpretation of the EM algorithm:\n",
        "\n",
        "- **E-step**: Assign each data point to the nearest cluster based on Euclidean distance.\n",
        "- **M-step**: Update the cluster centers as the mean of the points assigned to each cluster.\n",
        "- **SSE**: Compute the Sum of Squared Errors as the sum of squared Euclidean distances from each point to its assigned cluster center.\n",
        "- **Convergence**: Stop when the L1-distance between old and new centers is less than 0.0001 or after 100 iterations.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Implementing the EM Algorithm\n",
        "We’ll implement the algorithm in Python using NumPy and Pandas. Let’s go through the steps.\n",
        "\n",
        "#### Step 2.1: Load and Preprocess the Data\n",
        "First, we load the data from `Data_Q4.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-uXapkzCJrp",
        "outputId": "11ee186a-a771-423a-8617-9088284d29f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Notes/MSBD5002/Data_Q4\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Notes/MSBD5002/Data_Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ChoWZZbCANR",
        "outputId": "c2907b79-ea4c-4836-e3fa-afa4f9187936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of data: (626, 6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Q4_Data.csv')\n",
        "print(\"Shape of data:\", data.shape)  # Should be (626, 6)\n",
        "\n",
        "# Convert to numpy array\n",
        "X = data.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTY07tW3B_je"
      },
      "source": [
        "\n",
        "\n",
        "#### Step 2.2: Implement the EM Algorithm\n",
        "We’ll define the EM algorithm with the specified initial centers, iterate until convergence, and track the centers and SSE for the first two iterations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B6GMVbwWB3dr"
      },
      "outputs": [],
      "source": [
        "# Define the EM algorithm for clustering\n",
        "def em_clustering(X, initial_centers, max_iters=100, tol=0.0001):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - X: Data array of shape (n_samples, n_features)\n",
        "    - initial_centers: Initial cluster centers of shape (n_clusters, n_features)\n",
        "    - max_iters: Maximum number of iterations\n",
        "    - tol: Tolerance for convergence (L1-distance)\n",
        "    Returns:\n",
        "    - centers: Final cluster centers\n",
        "    - iteration_logs: List of (centers, SSE) for each iteration\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "    n_clusters = initial_centers.shape[0]\n",
        "\n",
        "    # Initialize centers\n",
        "    centers = initial_centers.copy()\n",
        "    iteration_logs = []\n",
        "\n",
        "    for iteration in range(max_iters):\n",
        "        # E-step: Assign points to the nearest cluster\n",
        "        distances = np.zeros((n_samples, n_clusters))\n",
        "        for k in range(n_clusters):\n",
        "            distances[:, k] = np.sum((X - centers[k]) ** 2, axis=1)  # Squared Euclidean distance\n",
        "        labels = np.argmin(distances, axis=1)  # Assign to nearest cluster\n",
        "\n",
        "        # Compute SSE (Sum of Squared Errors)\n",
        "        sse = 0\n",
        "        for k in range(n_clusters):\n",
        "            cluster_points = X[labels == k]\n",
        "            if len(cluster_points) > 0:\n",
        "                sse += np.sum((cluster_points - centers[k]) ** 2)\n",
        "\n",
        "        # M-step: Update cluster centers\n",
        "        new_centers = np.zeros_like(centers)\n",
        "        for k in range(n_clusters):\n",
        "            cluster_points = X[labels == k]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers[k] = np.mean(cluster_points, axis=0)\n",
        "            else:\n",
        "                new_centers[k] = centers[k]  # If cluster is empty, keep the old center\n",
        "\n",
        "        # Log the centers and SSE for this iteration\n",
        "        iteration_logs.append((centers.copy(), sse))\n",
        "\n",
        "        # Check for convergence using L1-distance\n",
        "        l1_distance = np.sum(np.abs(new_centers - centers))\n",
        "        centers = new_centers\n",
        "\n",
        "        if l1_distance < tol:\n",
        "            print(f\"Converged after {iteration + 1} iterations\")\n",
        "            break\n",
        "\n",
        "    if iteration == max_iters - 1:\n",
        "        print(f\"Reached maximum iterations ({max_iters})\")\n",
        "\n",
        "    return centers, iteration_logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIQfpWypClY7",
        "outputId": "9cccbbda-815f-46d6-e7dd-163a382cde6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converged after 11 iterations\n"
          ]
        }
      ],
      "source": [
        "# Initial centers\n",
        "initial_centers = np.array([\n",
        "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # c1\n",
        "    [1.1, 1.1, 1.1, 1.1, 1.1, 1.1]   # c2\n",
        "])\n",
        "\n",
        "# Run the EM algorithm\n",
        "final_centers, iteration_logs = em_clustering(X, initial_centers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ge1JYtxB1ss"
      },
      "source": [
        "- **E-step**: We compute the squared Euclidean distance from each point to each cluster center and assign the point to the nearest cluster.\n",
        "- **M-step**: We update each cluster center as the mean of the points assigned to that cluster.\n",
        "- **SSE**: We compute the Sum of Squared Errors as the sum of squared distances from each point to its assigned cluster center.\n",
        "- **Convergence**: We check the L1-distance (sum of absolute differences) between the old and new centers and stop if it’s less than 0.0001 or after 100 iterations.\n",
        "- **Logging**: We store the centers and SSE for each iteration to report the first two iterations.\n",
        "\n",
        "#### Step 2.3: Report the Results\n",
        "We need to report:\n",
        "1. The updated centers and SSE for the first two iterations.\n",
        "2. The final centers when the algorithm converges.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7yBJ7yCrpb",
        "outputId": "9ad7ca3b-085b-4bc5-eeb9-acce042e3ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Iteration:\n",
            "Centers:\n",
            "c1: [0. 0. 0. 0. 0. 0.]\n",
            "c2: [1.1 1.1 1.1 1.1 1.1 1.1]\n",
            "SSE: 530541.02\n",
            "\n",
            "Second Iteration:\n",
            "Centers:\n",
            "c1: [1.44444444 0.22222222 0.66666667 0.         0.         0.11111111]\n",
            "c2: [ 2.84602917  6.42139384 14.31604538  8.99351702  0.24311183  1.01620746]\n",
            "SSE: 325470.1898978879\n",
            "\n",
            "Final Centers:\n",
            "c1: [2.52037037 4.6037037  9.33888889 5.17037037 0.22222222 0.95      ]\n",
            "c2: [ 4.74418605 17.18604651 44.13953488 32.05813953  0.34883721  1.3372093 ]\n"
          ]
        }
      ],
      "source": [
        "# Report the updated centers and SSE for the first two iterations\n",
        "print(\"First Iteration:\")\n",
        "print(\"Centers:\")\n",
        "print(\"c1:\", iteration_logs[0][0][0])\n",
        "print(\"c2:\", iteration_logs[0][0][1])\n",
        "print(\"SSE:\", iteration_logs[0][1])\n",
        "\n",
        "print(\"\\nSecond Iteration:\")\n",
        "print(\"Centers:\")\n",
        "print(\"c1:\", iteration_logs[1][0][0])\n",
        "print(\"c2:\", iteration_logs[1][0][1])\n",
        "print(\"SSE:\", iteration_logs[1][1])\n",
        "\n",
        "# Report the final centers\n",
        "print(\"\\nFinal Centers:\")\n",
        "print(\"c1:\", final_centers[0])\n",
        "print(\"c2:\", final_centers[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O2_zdtjCq-x"
      },
      "source": [
        "- The `iteration_logs` list contains tuples of (centers, SSE) for each iteration. We access the first two entries for the first two iterations.\n",
        "- The `final_centers` variable contains the centers after convergence.\n",
        "\n",
        "#### Step 2.4: Package the Submission\n",
        "We need to submit the code and report in a folder named `Q4`. The report (`Q4_readme.pdf`) should include the updated centers and SSE for the first two iterations, the final centers, and the code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Co1g9PCw-d"
      },
      "source": [
        "- **Note**: The question asks for `Q4_readme.pdf`, so you’ll need to convert the code and report to PDF format manually (e.g., by copying the code and output into a document and saving as PDF).\n",
        "\n",
        "---\n",
        "\n",
        "### Step 3: Write the Report\n",
        "The report should include the updated centers and SSE for the first two iterations, the final centers, and the code. Here’s a summary to include in `Q4_readme.pdf`:\n",
        "\n",
        "#### Report Content\n",
        "\n",
        "1. **Introduction**:\n",
        "\n",
        "   - The task is to implement the Expectation-Maximization (EM) algorithm for clustering the data in `Q4_Data.csv` into two clusters (c1 and c2).\n",
        "   - The dataset contains 626 instances with 6 attributes.\n",
        "   - Initial centers:\n",
        "     - c1 = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "     - c2 = (1.1, 1.1, 1.1, 1.1, 1.1, 1.1)\n",
        "\n",
        "2. **Algorithm Description**:\n",
        "\n",
        "   - **E-step**: Assign each data point to the nearest cluster based on Euclidean distance.\n",
        "   - **M-step**: Update the cluster centers as the mean of the points assigned to each cluster.\n",
        "   - **SSE**: Compute the Sum of Squared Errors as the sum of squared distances from each point to its assigned cluster center.\n",
        "   - **Convergence**: Stop when the L1-distance between old and new centers is less than 0.0001 or after 100 iterations.\n",
        "\n",
        "3. **Results**:\n",
        "\n",
        "   - **First Iteration**:\n",
        "     - Centers:\n",
        "       - c1: [Output from iteration_logs[0][0][0]]\n",
        "       - c2: [Output from iteration_logs[0][0][1]]\n",
        "     - SSE: [Output from iteration_logs[0][1]]\n",
        "\n",
        "   - **Second Iteration**:\n",
        "     - Centers:\n",
        "       - c1: [Output from iteration_logs[1][0][0]]\n",
        "       - c2: [Output from iteration_logs[1][0][1]]\n",
        "     - SSE: [Output from iteration_logs[1][1]]\n",
        "\n",
        "   - **Final Centers**:\n",
        "     - c1: [Output from final_centers[0]]\n",
        "     - c2: [Output from final_centers[1]]\n",
        "\n",
        "4. **Code**:\n",
        "   - [Include the entire code from above]\n",
        "---\n",
        "\n",
        "### Final Submission\n",
        "Your submission folder `Q4` should contain:\n",
        "- `Q4_readme.pdf`: The report with the code, updated centers, and SSE for the first two iterations, and the final centers.\n",
        "\n",
        "**Folder Structure**:\n",
        "```\n",
        "Q4/\n",
        "└── Q4_readme.pdf\n",
        "```\n",
        "\n",
        "To create the PDF:\n",
        "\n",
        "1. Copy the report content above into a document editor.\n",
        "2. Include the actual output (centers and SSE) from running the code.\n",
        "3. Format it for clarity (e.g., use headings, bullet points).\n",
        "4. Export the document as a PDF named `Q4_readme.pdf`.\n",
        "5. Place the PDF in the `Q4` folder.\n",
        "\n",
        "---\n",
        "\n",
        "### Notes and Potential Improvements\n",
        "1. **EM vs. K-Means**: The problem uses EM terminology but describes a k-means-like algorithm. A true EM algorithm for clustering would involve Gaussian Mixture Models (GMMs) with soft assignments (probabilities), covariance matrices, and maximization of the likelihood. If the problem intended a GMM, we’d need to modify the implementation to include these components.\n",
        "2. **Empty Clusters**: The code handles empty clusters by keeping the old center, but in a real scenario, you might reinitialize the center randomly.\n",
        "3. **Data Preprocessing**: The problem doesn’t specify preprocessing, but in practice, you might normalize the data if the features have different scales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4AAdxoWC3fK"
      },
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
